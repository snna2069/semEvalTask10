{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13703790,"sourceType":"datasetVersion","datasetId":8717410}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code]\n# ================================\n# 1) ENV REPAIR & DEPENDENCIES\n#    (Run ONCE, then Restart the kernel)\n# ================================\n!pip -q install -U \"protobuf<5\" \"pyarrow>=14,<20\" \\\n  \"transformers==4.44.2\" \"datasets==2.19.0\" \\\n  \"accelerate==1.0.1\" \"evaluate==0.4.2\" \\\n  \"sentencepiece==0.2.0\" \"scikit-learn==1.5.2\"\n\nimport sys, subprocess\nprint(\"Python:\", sys.version)\nsubprocess.run([\n    \"python\", \"-c\",\n    \"import google.protobuf, pyarrow as pa, transformers, datasets, sklearn, evaluate, sentencepiece;\"\n    \"import google.protobuf; print('protobuf:', google.protobuf.__version__);\"\n    \"print('pyarrow:', pa.__version__);\"\n    \"print('transformers:', transformers.__version__);\"\n    \"print('datasets:', datasets.__version__);\"\n    \"import sklearn; print('sklearn:', sklearn.__version__);\"\n    \"import evaluate; print('evaluate:', evaluate.__version__);\"\n    \"import sentencepiece; import torch; import platform;\"\n    \"print('torch:', torch.__version__); print('platform:', platform.platform())\"\n])\nprint(\"\\nNow go to Runtime â†’ Restart. Then continue with the next cell.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %% [code]\n# ================================\n# 2) IMPORTS & CONFIG\n# ================================\nimport os\nimport json\nimport random\nimport math\nimport numpy as np\nimport pandas as pd\n\nimport torch\n\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset, DatasetDict\nimport evaluate\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    TrainingArguments,\n    Trainer,\n    set_seed,\n)\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nset_seed(SEED)\n\n# Model (compact multilingual; practical alternative to \"DistilXLM-RoBERTa-base\")\nMODEL_NAME = \"distilbert/distilbert-base-multilingual-cased\"\n\n# Where Kaggle might place your JSON\nCANDIDATE_PATHS = [\n    \"/kaggle/input/train-data/train_data.json\"    # e.g., Dataset named 'train_data'\n]\n\nDATA_PATH = next((p for p in CANDIDATE_PATHS if os.path.exists(p)), None)\nassert DATA_PATH is not None, f\"Couldn't find train_data.json in {CANDIDATE_PATHS}. Add it as a Kaggle input.\"\n\nprint(\"Using data:\", DATA_PATH)\nprint(\"GPU available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T05:37:11.994668Z","iopub.execute_input":"2025-11-13T05:37:11.994946Z","iopub.status.idle":"2025-11-13T05:37:22.381609Z","shell.execute_reply.started":"2025-11-13T05:37:11.994925Z","shell.execute_reply":"2025-11-13T05:37:22.380862Z"}},"outputs":[{"name":"stderr","text":"2025-11-13 05:37:16.914968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763012236.937845     125 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763012236.944719     125 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Using data: /kaggle/input/train-data/train_data.json\nGPU available: True\nCUDA device: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# %% [code]\n# ================================\n# 3) LOAD & PREP DATA\n# ================================\nwith open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\ndf = pd.DataFrame(data)\n\n# Keep columns we need; predict 'validity' from 'syllogism'\nneeded = [\"syllogism\", \"validity\"]\nmissing = [c for c in needed if c not in df.columns]\nassert not missing, f\"Missing columns in JSON: {missing}\"\n\ndf = df[needed].dropna().reset_index(drop=True)\ndf[\"label\"] = df[\"validity\"].astype(int)\ndf = df.rename(columns={\"syllogism\": \"text\"})\n\nprint(df.head(3))\nprint(\"\\nLabel distribution (0=invalid, 1=valid):\")\nprint(df[\"label\"].value_counts(normalize=True).round(3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T05:37:25.271112Z","iopub.execute_input":"2025-11-13T05:37:25.272137Z","iopub.status.idle":"2025-11-13T05:37:25.311770Z","shell.execute_reply.started":"2025-11-13T05:37:25.272106Z","shell.execute_reply":"2025-11-13T05:37:25.310882Z"}},"outputs":[{"name":"stdout","text":"                                                text  validity  label\n0  All cars are a type of vehicle. No animal is a...     False      0\n1  Nothing that is a soda is a juice. A portion o...      True      1\n2  Everything that is a planet is a celestial bod...     False      0\n\nLabel distribution (0=invalid, 1=valid):\nlabel\n0    0.5\n1    0.5\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# %% [code]\n# ================================\n# 4) TRAIN / VALIDATION SPLIT\n# ================================\ntrain_df, val_df = train_test_split(\n    df[[\"text\", \"label\"]],\n    test_size=0.15,\n    random_state=SEED,\n    stratify=df[\"label\"]\n)\n\nds = DatasetDict({\n    \"train\": Dataset.from_pandas(train_df.reset_index(drop=True)),\n    \"validation\": Dataset.from_pandas(val_df.reset_index(drop=True)),\n})\n\nlen(ds[\"train\"]), len(ds[\"validation\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T05:37:29.176706Z","iopub.execute_input":"2025-11-13T05:37:29.177000Z","iopub.status.idle":"2025-11-13T05:37:29.220841Z","shell.execute_reply.started":"2025-11-13T05:37:29.176978Z","shell.execute_reply":"2025-11-13T05:37:29.220245Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(816, 144)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# %% [code]\n# ================================\n# 5) TOKENIZATION\n# ================================\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n\ndef tok_fn(batch):\n    return tokenizer(batch[\"text\"], truncation=True)\n\ncols_to_remove = [c for c in ds[\"train\"].column_names if c not in [\"text\", \"label\"]]\nds_tok = ds.map(tok_fn, batched=True, remove_columns=cols_to_remove)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\nprint(ds_tok)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T05:37:31.723227Z","iopub.execute_input":"2025-11-13T05:37:31.723874Z","iopub.status.idle":"2025-11-13T05:37:32.889258Z","shell.execute_reply.started":"2025-11-13T05:37:31.723846Z","shell.execute_reply":"2025-11-13T05:37:32.888487Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3bcd66f35894cfcb1f0d2ed33eb38b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a2fc44b210e45eda8c3a25147ecbe04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75d8236d7862418aa241df1399e047d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"711ff76a6ed94f8a9e5e89c3a608f2a2"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/816 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69bf967166e84660bfc323ffb69fb7d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/144 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ef757cf0252421ab05401be13fa67ce"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 816\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 144\n    })\n})\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# %% [code]\n# ================================\n# 6) METRICS  (updated to match screenshot keys)\n# ================================\nimport evaluate\naccuracy_metric  = evaluate.load(\"accuracy\")\nprecision_metric = evaluate.load(\"precision\")\nrecall_metric    = evaluate.load(\"recall\")\nf1_metric        = evaluate.load(\"f1\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=1)\n    return {\n        \"accuracy\":  accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n        \"precision\": precision_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"precision\"],\n        \"recall\":    recall_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"recall\"],\n        \"f1\":        f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"],\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T05:37:35.374381Z","iopub.execute_input":"2025-11-13T05:37:35.375126Z","iopub.status.idle":"2025-11-13T05:37:38.560799Z","shell.execute_reply.started":"2025-11-13T05:37:35.375093Z","shell.execute_reply":"2025-11-13T05:37:38.560229Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d38e16a379ef4118931c48361f2ae733"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cde37e67d0754de19063c4770e9c8976"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a532756e8df745959148a6f3411c7cd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ae63eff67894f12a2d55c50296b6a0d"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# %% [code]\n# ================================\n# 7) MODEL & TRAINING ARGS  (GPU-HEAVY)\n# ================================\nnum_labels = 2\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=num_labels\n)\n\nEPOCHS =  5           \nBSZ = 16\nLR = 2e-5\nWD = 0.01\nGRAD_ACCUM = 1\nLOG_STEPS = 50\n\nargs = TrainingArguments(\n    output_dir=\"outputs\",\n    learning_rate=LR,\n    per_device_train_batch_size=BSZ,\n    per_device_eval_batch_size=BSZ,\n    gradient_accumulation_steps=GRAD_ACCUM,\n    num_train_epochs=EPOCHS,\n    weight_decay=WD,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",   # â† track best by F1 (matches summary cell)\n    greater_is_better=True,\n    fp16=torch.cuda.is_available(),\n    report_to=\"none\",\n    logging_steps=LOG_STEPS,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=ds_tok[\"train\"],\n    eval_dataset=ds_tok[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrain_result = trainer.train()\ntrain_result.metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T05:39:22.339310Z","iopub.execute_input":"2025-11-13T05:39:22.340044Z","iopub.status.idle":"2025-11-13T05:40:14.619917Z","shell.execute_reply.started":"2025-11-13T05:39:22.340018Z","shell.execute_reply":"2025-11-13T05:40:14.619234Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='255' max='255' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [255/255 00:51, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.662100</td>\n      <td>0.588391</td>\n      <td>0.687500</td>\n      <td>0.701534</td>\n      <td>0.687500</td>\n      <td>0.681963</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.508200</td>\n      <td>0.563485</td>\n      <td>0.715278</td>\n      <td>0.720423</td>\n      <td>0.715278</td>\n      <td>0.713607</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.373400</td>\n      <td>0.557983</td>\n      <td>0.729167</td>\n      <td>0.739564</td>\n      <td>0.729167</td>\n      <td>0.726196</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.305700</td>\n      <td>0.549362</td>\n      <td>0.777778</td>\n      <td>0.779720</td>\n      <td>0.777778</td>\n      <td>0.777391</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.248300</td>\n      <td>0.543782</td>\n      <td>0.791667</td>\n      <td>0.791892</td>\n      <td>0.791667</td>\n      <td>0.791626</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'train_runtime': 51.5252,\n 'train_samples_per_second': 79.185,\n 'train_steps_per_second': 4.949,\n 'total_flos': 47162533527744.0,\n 'train_loss': 0.41638573291254977,\n 'epoch': 5.0}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# %% [code]\n# ================================\n# 8) EVALUATE (GPU-OK but fast)\n# ================================\nmetrics = trainer.evaluate()\nmetrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T05:40:14.800019Z","iopub.execute_input":"2025-11-13T05:40:14.800216Z","iopub.status.idle":"2025-11-13T05:40:20.243029Z","shell.execute_reply.started":"2025-11-13T05:40:14.800201Z","shell.execute_reply":"2025-11-13T05:40:20.242418Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.5437819957733154,\n 'eval_accuracy': 0.7916666666666666,\n 'eval_precision': 0.791891891891892,\n 'eval_recall': 0.7916666666666666,\n 'eval_f1': 0.7916264711557013,\n 'eval_runtime': 0.1655,\n 'eval_samples_per_second': 870.267,\n 'eval_steps_per_second': 54.392,\n 'epoch': 5.0}"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# %% [code]\n# ================================\n# 8b) SUMMARY PRINTER + BEST EPOCH\n# ================================\nfrom pprint import pprint\n\n# Grab all eval logs (one per epoch) from HF Trainer state\neval_logs = [e for e in trainer.state.log_history if isinstance(e, dict) and \"eval_accuracy\" in e]\n\nif len(eval_logs) == 0:\n    # Fallback: run a fresh eval now\n    current = trainer.evaluate()\n    print(current)\n    best_epoch = None\n    best_log = None\nelse:\n    # Print the final (last) eval dict like your top line\n    last_eval = eval_logs[-1]\n    pprint(last_eval)\n    print(\"\\nEvaluating on validation data...\")\n    # Run one immediate eval (mirrors your second line in screenshot)\n    current = trainer.evaluate()\n    pprint(current)\n\n    # Final Validation Summary block\n    print(\"\\nFinal Validation Summary:\")\n    print(f\"  Accuracy:  {current.get('eval_accuracy', 0):.4f}\")\n    print(f\"  F1 Score:  {current.get('eval_f1', 0):.4f}\")\n    print(f\"  Precision: {current.get('eval_precision', 0):.4f}\")\n    print(f\"  Recall:    {current.get('eval_recall', 0):.4f}\")\n\n    # Determine best epoch by highest eval_f1 among eval logs\n    best_log = max(eval_logs, key=lambda d: d.get(\"eval_f1\", float('-inf')))\n    best_epoch = best_log.get(\"epoch\", None)\n\n# Also show best checkpoint (Trainer tracked)\nbest_ckpt = getattr(trainer.state, \"best_model_checkpoint\", None)\n\nif best_epoch is not None:\n    print(\"\\nBest Epoch Summary (by F1):\")\n    print(f\"  Best epoch: {best_epoch}\")\n    print(f\"  Accuracy:   {best_log.get('eval_accuracy', 0):.4f}\")\n    print(f\"  F1 Score:   {best_log.get('eval_f1', 0):.4f}\")\n    print(f\"  Precision:  {best_log.get('eval_precision', 0):.4f}\")\n    print(f\"  Recall:     {best_log.get('eval_recall', 0):.4f}\")\nif best_ckpt:\n    print(f\"  Best checkpoint: {best_ckpt}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T05:40:22.132167Z","iopub.execute_input":"2025-11-13T05:40:22.132915Z","iopub.status.idle":"2025-11-13T05:40:22.311048Z","shell.execute_reply.started":"2025-11-13T05:40:22.132889Z","shell.execute_reply":"2025-11-13T05:40:22.310424Z"}},"outputs":[{"name":"stdout","text":"{'epoch': 5.0,\n 'eval_accuracy': 0.7916666666666666,\n 'eval_f1': 0.7916264711557013,\n 'eval_loss': 0.5437819957733154,\n 'eval_precision': 0.791891891891892,\n 'eval_recall': 0.7916666666666666,\n 'eval_runtime': 0.1655,\n 'eval_samples_per_second': 870.267,\n 'eval_steps_per_second': 54.392,\n 'step': 255}\n\nEvaluating on validation data...\n{'epoch': 5.0,\n 'eval_accuracy': 0.7916666666666666,\n 'eval_f1': 0.7916264711557013,\n 'eval_loss': 0.5437819957733154,\n 'eval_precision': 0.791891891891892,\n 'eval_recall': 0.7916666666666666,\n 'eval_runtime': 0.1667,\n 'eval_samples_per_second': 864.048,\n 'eval_steps_per_second': 54.003}\n\nFinal Validation Summary:\n  Accuracy:  0.7917\n  F1 Score:  0.7916\n  Precision: 0.7919\n  Recall:    0.7917\n\nBest Epoch Summary (by F1):\n  Best epoch: 5.0\n  Accuracy:   0.7917\n  F1 Score:   0.7916\n  Precision:  0.7919\n  Recall:     0.7917\n  Best checkpoint: outputs/checkpoint-255\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# %% [code]\n# ================================\n# 9) SAVE MODEL + TOKENIZER\n# ================================\nSAVE_DIR = \"model_validity_distilmbert_multilingual\"\ntrainer.save_model(SAVE_DIR)\ntokenizer.save_pretrained(SAVE_DIR)\nprint(\"Saved to:\", SAVE_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T05:40:27.636927Z","iopub.execute_input":"2025-11-13T05:40:27.637745Z","iopub.status.idle":"2025-11-13T05:40:28.980134Z","shell.execute_reply.started":"2025-11-13T05:40:27.637717Z","shell.execute_reply":"2025-11-13T05:40:28.979514Z"}},"outputs":[{"name":"stdout","text":"Saved to: model_validity_distilmbert_multilingual\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# %% [code]\n# ================================\n# 10) QUICK INFERENCE DEMO (GPU-ACCELERATED IF AVAILABLE)\n# ================================\nex_texts = [\n    \"All mammals are animals. All dogs are mammals. Therefore, all dogs are animals.\",\n    \"No birds are mammals. Some whales are mammals. Therefore, some whales are birds.\",\n]\nenc = tokenizer(ex_texts, padding=True, truncation=True, return_tensors=\"pt\").to(model.device)\nwith torch.no_grad():\n    logits = model(**enc).logits\npreds = logits.argmax(dim=1).cpu().tolist()\n\nfor t, p in zip(ex_texts, preds):\n    print(f\"[pred={p}] {t}\")\nprint(\"\\n(1 = formally valid, 0 = not valid)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T05:40:29.883090Z","iopub.execute_input":"2025-11-13T05:40:29.883714Z","iopub.status.idle":"2025-11-13T05:40:29.917029Z","shell.execute_reply.started":"2025-11-13T05:40:29.883688Z","shell.execute_reply":"2025-11-13T05:40:29.916258Z"}},"outputs":[{"name":"stdout","text":"[pred=0] All mammals are animals. All dogs are mammals. Therefore, all dogs are animals.\n[pred=0] No birds are mammals. Some whales are mammals. Therefore, some whales are birds.\n\n(1 = formally valid, 0 = not valid)\n","output_type":"stream"}],"execution_count":13}]}